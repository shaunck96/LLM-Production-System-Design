# Databricks notebook source
!pip install bandit flake8 pylint mypy radon safety vulture


# COMMAND ----------

import os
import subprocess
import urllib.request
import zipfile
import concurrent.futures
import csv
import logging
from typing import List, Dict, Any, Optional

class StaticAnalysis:
    def __init__(self, src_folder: str, output_dir: str, requirements_file: str, repo_path: str, dependency_output_file: str, csv_output_file: str, code_security_folder: str):
        self.src_folder = src_folder
        self.output_dir = output_dir
        self.requirements_file = requirements_file
        self.repo_path = repo_path
        self.dependency_output_file = dependency_output_file
        self.csv_output_file = csv_output_file
        self.code_security_folder = code_security_folder
        self.results: Dict[str, Any] = {}

        # Ensure required directories exist
        for directory in [self.output_dir, self.code_security_folder]:
            os.makedirs(directory, exist_ok=True)

        # Create separate folders for each test
        self.test_folders = {
            "Bandit": os.path.join(self.output_dir, "bandit_results"),
            "Flake8": os.path.join(self.output_dir, "flake8_results"),
            "Pylint": os.path.join(self.output_dir, "pylint_results"),
            "Mypy": os.path.join(self.output_dir, "mypy_results"),
            "Radon": os.path.join(self.output_dir, "radon_results")
        }
        for folder in self.test_folders.values():
            os.makedirs(folder, exist_ok=True)

        # Set up logging
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                            filename=os.path.join(self.output_dir, 'static_analysis.log'))
        self.logger = logging.getLogger(__name__)

    def run_tool(self, tool_name: str, cmd: List[str], file_path: Optional[str] = None, output_file: Optional[str] = None) -> str:
        """Generic function to run a tool and capture its output."""
        self.logger.info(f"Running {tool_name} on {cmd[-1]}")
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            output = result.stdout + result.stderr
            passed = result.returncode == 0

            # Determine result
            if file_path:
                if file_path not in self.results:
                    self.results[file_path] = {}
                self.results[file_path][tool_name] = "Passed" if passed else "Failed"

                # Store result in the appropriate folder
                if tool_name in self.test_folders:
                    output_file = os.path.join(self.test_folders[tool_name], f"{os.path.basename(file_path)}.txt")
                    with open(output_file, 'w') as f:
                        f.write(output)
            else:
                self.results[tool_name] = "Passed" if passed else "Failed"

                # Store result for project-wide tools
                if output_file:
                    with open(output_file, 'w') as f:
                        f.write(output)
        
            return f"{tool_name} Results (Exit Code: {result.returncode}):\n{output}\n\n"
        except Exception as e:
            self.logger.error(f"Unexpected error running {tool_name}: {e}")
            return f"Unexpected error running {tool_name}: {str(e)}\n\n"

    def run_all_tests(self):
        tasks = []

        with concurrent.futures.ThreadPoolExecutor() as executor:
            # Walk through the directory and run checks on all .py files
            for root, dirs, files in os.walk(self.src_folder):
                for file in files:
                    if file.endswith(".py"):
                        file_path = os.path.join(root, file)
                        
                        # Schedule tests in parallel
                        tasks.append(executor.submit(self.run_tool, "Bandit", ['bandit', '-r', file_path], file_path))
                        tasks.append(executor.submit(self.run_tool, "Flake8", ['flake8', '--max-line-length=120', '--ignore=E203,E266,E501,W503', file_path], file_path))
                        tasks.append(executor.submit(self.run_tool, "Pylint", ['pylint', '--disable=C0301,C0325,C0326,C0330,C0411,C0412,W0611,W0612,W0613', file_path], file_path))
                        tasks.append(executor.submit(self.run_tool, "Mypy", ['mypy', '--ignore-missing-imports', '--allow-untyped-defs', file_path], file_path))
                        tasks.append(executor.submit(self.run_tool, "Radon", ['radon', 'cc', file_path, '-a'], file_path))

            # Schedule project-wide checks
            safety_output = os.path.join(self.code_security_folder, "safety_results.txt")
            tasks.append(executor.submit(self.run_tool, "Safety", ['safety', 'check', '--file', self.requirements_file, '--full-report', '--ignore=42194'], output_file=safety_output))
            
            bandit_output = os.path.join(self.code_security_folder, "bandit_results.txt")
            tasks.append(executor.submit(self.run_tool, "Bandit", ['bandit', '-r', self.src_folder, '-f', 'custom'], output_file=bandit_output))
            
            tasks.append(executor.submit(self.run_tool, "Vulture", ['vulture', self.src_folder]))

            # Collect all results
            results = [task.result() for task in concurrent.futures.as_completed(tasks)]

        # Write all results to the output file
        with open(os.path.join(self.output_dir, 'static_analysis_report.txt'), 'w') as report:
            report.writelines(results)

        self.logger.info(f"Static analysis completed. Report saved to {self.output_dir}")

        # Generate CSV report
        self.generate_csv_report()

    def run_dependency_check(self, dependency_check_bin: str):
        try:
            self.logger.info(f"Running OWASP Dependency-Check on {self.requirements_file}")
            result = subprocess.run(
                [dependency_check_bin, "--project", "MyProject", "--scan", self.requirements_file, "--format", "HTML", "--out", self.dependency_output_file, "-v"],
                capture_output=True, text=True, check=True
            )

            # Store the result
            self.results["OWASP Dependency-Check"] = "Passed" if result.returncode == 0 else "Failed"

            self.logger.info(f"Dependency-Check completed. Report saved to {self.dependency_output_file}")
            self.logger.info(result.stdout)  # Log the standard output of the Dependency-Check

        except subprocess.CalledProcessError as e:
            self.logger.error(f"Error running Dependency-Check: {e.output}")
            self.results["OWASP Dependency-Check"] = "Failed"
        except Exception as e:
            self.logger.error(f"Unexpected error running Dependency-Check: {str(e)}")
            self.results["OWASP Dependency-Check"] = "Failed"

    def generate_csv_report(self):
        with open(self.csv_output_file, 'w', newline='') as csvfile:
            fieldnames = ['File', 'Bandit', 'Flake8', 'Pylint', 'Mypy', 'Radon']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            writer.writeheader()
            for file_path, results in self.results.items():
                if isinstance(results, dict):  # This is a file-specific result
                    row = {'File': file_path}
                    row.update(results)
                    writer.writerow(row)

            # Write project-wide results
            writer.writerow({})
            writer.writerow({'File': 'Project-wide Tests'})
            for test, result in self.results.items():
                if not isinstance(result, dict):  # This is a project-wide result
                    writer.writerow({'File': test, 'Bandit': result})

        self.logger.info(f"CSV report generated: {self.csv_output_file}")

def download_and_extract_dependency_check(url: str, download_path: str, extraction_path: str):
    # Download the Dependency-Check CLI zip file
    if not os.path.exists(download_path):
        logging.info(f"Downloading Dependency-Check CLI from {url}")
        urllib.request.urlretrieve(url, download_path)
        logging.info(f"Downloaded to {download_path}")

    # Extract the Dependency-Check CLI zip file
    if not os.path.exists(extraction_path):
        logging.info(f"Extracting Dependency-Check CLI to {extraction_path}")
        with zipfile.ZipFile(download_path, 'r') as zip_ref:
            zip_ref.extractall(extraction_path)
        logging.info(f"Extracted to {extraction_path}")
    else:
        logging.info("Dependency-Check CLI already extracted.")

def main():
    # Paths and URLs
    dependency_check_url = "https://github.com/jeremylong/DependencyCheck/releases/download/v6.5.3/dependency-check-6.5.3-release.zip"
    download_path = "/dbfs/FileStore/dependency-check/dependency-check-cli.zip"
    extraction_path = "/dbfs/FileStore/dependency-check/extracted/"
    src_folder = '/src'
    output_dir = '/code_quality_vulnerability_scan/test_results'
    requirements_file = '/src/requirements.txt'
    repo_path = '/src'
    dependency_output_file = os.path.join(output_dir, "dependency_check_report.html")
    csv_output_file = os.path.join(output_dir, "test_results.csv")
    dependency_check_bin = os.path.join(extraction_path, "dependency-check", "bin", "dependency-check.sh")
    code_security_folder = os.path.join(output_dir, "code_security")

    # Download and extract Dependency-Check CLI
    download_and_extract_dependency_check(dependency_check_url, download_path, extraction_path)

    # Run the static analysis
    analysis = StaticAnalysis(src_folder, output_dir, requirements_file, repo_path, dependency_output_file, csv_output_file, code_security_folder)
    analysis.run_all_tests()

    # Run OWASP Dependency-Check
    analysis.run_dependency_check(dependency_check_bin)

if __name__ == "__main__":
    main()


# COMMAND ----------

